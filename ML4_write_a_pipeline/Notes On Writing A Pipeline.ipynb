{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to write a basic pipeline for supervised learning, and look at how multiple classifiers can be used to solve the same problem. Then, I'll build a little more intuition for what it means for an algorithm to learn something from data (this sounds magical but it's not).\n",
    "\n",
    "Imagine your're building up a spam classifier.\n",
    "![spam classifier](./assets/spamClassifier.png)\n",
    "This is just a function that labels an email as spam or not spam. Say you've already collected a dataset and you're ready to train a model.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Email</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Click here to claim your prize!</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What's new?</td>\n",
       "      <td>Not spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hang out later?</td>\n",
       "      <td>Not spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You have won $1000,000</td>\n",
       "      <td>Spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Email     Label\n",
       "0  Click here to claim your prize!      Spam\n",
       "1                      What's new?  Not spam\n",
       "2                  Hang out later?  Not spam\n",
       "3           You have won $1000,000      Spam\n",
       "4                              ...       ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"Email\":[\"Click here to claim your prize!\",\"What's new?\",\"Hang out later?\",\"You have won $1000,000\",\"...\"],\n",
    "              \"Label\":[\"Spam\",\"Not spam\",\"Not spam\",\"Spam\",\"...\"]\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But before you put it into production there's a question you need to answer first. How accurate will it be when you need it to classify emails that weren't in you're training data. We want to verify our models work well before we deploy them. You can do an experiment to help you figure this out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![train and test](./assets/spamDataset2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One approach is to partition your data into two parts. Call these _TRAIN_ and _TEST_.\n",
    "\n",
    "* Train: use train to train the model.\n",
    "* Test: use test to see how accurate it is on new data.\n",
    "\n",
    "This is a common pattern so let's see how it looks in code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a dataset into scikit\n",
    "from sklearn import datasets\n",
    "\n",
    "# using iris because it's provided by scikit\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# I've already used Iris in module 2\n",
    "# what I havn't done before is...\n",
    "# I'm calling the features \"X\" and the target \"labels\"\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason I'm using _X_ and _y_ is that I can think of a classifier as a function. Think of X as the input (i.e. Features) and y as the output (i.e. label).\n",
    "\n",
    "```python\n",
    "f(x) = y\n",
    "```\n",
    "After importing the dataset, it needs to be partitioned. Use the utility below because it is handy, and the syntax is clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using model selection because cross_validation will be depricated in version 0.20.\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_test, X_train, y_test, y_train = train_test_split(X, y, test_size = .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is taking our X's and y's (i.e. features and labels) and partitioning them into two sets. *X_train* and *y_train* are the features & labels for the training set, and *X_test* and *y_test* are the features & labels for the testing set. The paramaeter *test_size* is set to 0.5 to split the data into equal sets. In this case, 75 records will be in training, and the other 75 will be in testing.\n",
    "\n",
    "Now let's create the classifier. I'm going to use two different types of classifier to show how they accomplish the same task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starting with the decision tree\n",
    "# this was covered in previous module\n",
    "# Note there are only two lines of code that are classifier specific.\n",
    "from sklearn import tree\n",
    "classifier = tree.DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the classifier with data\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point the classifier is ready to be used to classifiy data\n",
    "# call the predict method to classify your testing data\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 0 0 2 2 2 0 0 1 1 2 2 2 0 0 0 2 1 2 2 2 2 2 1 1 2 0 1 1 2 0 1 0 1 2 1\n",
      " 2 1 1 2 0 0 0 2 2 0 2 2 2 2 2 0 1 1 1 0 0 1 2 1 2 2 0 0 1 2 2 2 0 2 0 1 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "# print out the predictions to see \n",
    "# the list of numbers correspond to the type of iris the classifier predicts for each row in the testing data\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92\n"
     ]
    }
   ],
   "source": [
    "# now let's look at how accurate the classifier was on the testing set\n",
    "# recall you have the true labels for the testing data located in variable \"Y_test\"\n",
    "# to calculate the accuracy, you can compare the predicted labels to the true labels and tally up the score\n",
    "# there's a convenience method in scikit you can import to do this\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the accuracy here is over 90%. The score may vary between trials due to the randomness in how the train / test data is partitioned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for something interesting. By replacing these two lines of code, you can use a different classifier to accomplish the same task.\n",
    "\n",
    "```python\n",
    "from sklearn import tree\n",
    "tree_classifier = tree.DecisionTreeClassifier()\n",
    "```\n",
    "\n",
    "Instead of using a decision tree, I'm going to use one called k-nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using a new classifier to perform the same task\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run your experiment, you'll see that the code worked in exactly the same way. The accuracy may be different from decision tree classifier works differently than k-nearest neighbors, and because of the randomness in train / test split. Likewise, if I wanted to use a more sophisticated classifier I could ust import it and change these two lines. Otherwise, the code is the same.\n",
    "\n",
    "```python\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "```\n",
    "\n",
    "The reamining code runs the same as code in decision tree (above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the classifier with data\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point the classifier is ready to be used to classifiy data\n",
    "# call the predict method to classify your testing data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 0 0 0 1 2 2 0 0 1 1 2 2 2 0 0 0 2 1 2 2 2 1 2 1 1 2 0 1 1 2 0 1 0 1 2 1\n",
      " 2 1 1 2 0 0 0 2 2 0 2 2 2 2 1 0 1 1 1 0 0 1 2 1 2 2 0 0 1 2 2 2 0 2 0 2 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "# print out the predictions to see \n",
    "# the list of numbers correspond to the type of iris the classifier predicts for each row in the testing data\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "# now let's look at how accurate the classifier was on the testing set\n",
    "# recall you have the true labels for the testing data located in variable \"Y_test\"\n",
    "# to calculate the accuracy, you can compare the predicted labels to the true labels and tally up the score\n",
    "# there's a convenience method in scikit you can import to do this\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The takeaway here is that although there are many types of classifiers, at a high level they have a similar interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning from Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does it mean to learn from data?\n",
    "\n",
    "Earlier I stated featurs are called \"X\" and labels \"y\", beacuse they are the input and output of a function.Â I already know what a funciton is from programming:\n",
    "\n",
    "```python\n",
    "def classify(features):\n",
    "    # do some logic\n",
    "    return label\n",
    "```\n",
    "\n",
    "From the perspective of _supervised learning_, I don't want to write the code above by hand; because I want an algorithm to learn it from traning data. So what does it mean to learn a function. A function is just a mapping from input to output values, for example:\n",
    "\n",
    "```python\n",
    "y = mx+b\n",
    "```\n",
    "\n",
    "This is the equation for a line and there are two parameters:\n",
    "* m: gives the slope\n",
    "* b: gives the y-int\n",
    "\n",
    "Given these parameters you can plot the values for x. In regards to supervised learning, my classify function might have some parameters as well. But, the input _X_ are the _features_ I want to classify, and the output _y_ is a _label_ (i.e. spam or not spam, or the type of flower). \n",
    "\n",
    "# <span style = \"color:red\"> IMAGE <span>\n",
    "\n",
    "What can the body of a function look like? This is the part you want to write algorithmically (i.e. learn). The important thing to understand here is that you are not starting from scratch and pullig the body of the funciton out of thin air. Instead, you start with a model. Think of a model as the _prototype_ or fhe _rules_ that define the body of your function. Typically a model has perameters that you can adjust with your training data.\n",
    "\n",
    "# <span style = \"color:red\"> IMAGE <span>\n",
    "    \n",
    "\n",
    "Let's say you're trying to destinguish between red dots and green dots. To do this I'll use the x & y coordinates of a dot. How can you classify this data? You want a function to consider a new dot it's never seen before and  classifies it as red or green; or maybe you have a lot of data you want to classifery (i.e. a lot of dots the classifier has never seen before). These are dots that weren't in our training data. Since the classifier has never seen them before, how can you predict the right label? Imagine if you could draw a line across the data. Then you could say the dots to the left of the line are green and the dots to the right of the line are red; and this line can serve as your classifier.\n",
    "    \n",
    "# <span style = \"color:red\"> IMAGE <span>\n",
    "    \n",
    "\n",
    "So how can you learn this line? One way is to use this training data to adjust the parameters of this model, and the model you use is a simple straight line (like the one shown above). That means you have two parameters to adjust; _m_ and _b_, and by changing them you can change where the line appears. So, how can you learn the right parameters? One idea is that you can iteratively adjust them using the training data. For example, you might start with a random line, then use it to classify your first example. If the classifier gets the right, you don't need to change the line, and move on to the next example. But if it gets it wrong, you can slightly adjust the parameters of the model to make it more accurate. The takeaway here is, one way to think of learning is is using training data to adjust the parameters of a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Write a pipeline](https://www.youtube.com/watch?v=84gqSbLcBFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tensorflow Playground](): For future study. Tensorflow is an example of a neural network you can run and experiment with in your browser. Think of a neuarl network as a more sophisticated type of classifier (like a decision tree or a simple line), but in principle the idea is similar. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
