{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say you want to build a classifier that can tell the difference between a picture of T-Rex and a triceratops.\n",
    "![dinosuars](./assets/dinosaur.png)\n",
    "\n",
    "Or a painting as being a Monet or a Picasso.\n",
    "![paintins](./assets/art.png)\n",
    "\n",
    "To do this I'm going to work with a codelab called [TensorFlow for Poets](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0). This is a great way to start learning about and workiing with image classification.\n",
    "* This code lab is high level: to train the classifier I'll basiclly need to run a couple of scripts.\n",
    "* Powerful classifier: although the code lab is high level, but it's impresseive what the classifier can create. It's better than what a google-developer could have written just a couple of years ago."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train an image classifier with _TensorFlow for Poets_, I'll only need to provide one thing:\n",
    "* Training data\n",
    "\n",
    "In this case, it's just directories full of images. My plan is to create a classifier to tell the difference between five types of flowers: \n",
    "1. Daisy\n",
    "* Dandelion\n",
    "* Roses\n",
    "* Sunflowers\n",
    "* Tulips\n",
    "\n",
    "And here's what the training data looks like. Notice there are five directories; one for each type of flower. If you want to use your own images, say, for dinosaurs, or paintings, all you need to do is create a directory and fill it with images. Each directory needs about 100 images to start.\n",
    "![flower directory](./assets/directory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my Mac, I opened the termial, navigated the project directory and ran the following code:\n",
    "```unix\n",
    "curl http://download.tensorflow.org/example_images/flower_photos.tgz | tar xz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that I have the tarining data, the next thing I need to do is train my classifier. For this, I'll use TensorFlow. TensorFlow is an open source machine learning library, and is especially useful for workind with the branch of machine learning called deep learning.\n",
    "\n",
    "Deep learning has lead to great results in the last couple years. Especially in domains like image classification (which is what I'll be working with today). Here's one reason why: \n",
    "* Recall: In the firstmodule I discussed the difference between apples and oranges. It's impossible to do this by hand because there is too much variation in the world. But, I now know that classififires take featurs as input; and with images it's incredibly hard to extract useful features by hand. For example: you wouldn't want to detect the texture of a piece of fruit. To get aroudn this, I will use deep learning, because it has a major advantage when working with images, and it's this. You don't need to extract features manually. Instead, you can use the raw pixels of the image's features, and the classifier will do the rest. \n",
    "![raw pixels](./assets/rawPixels.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the difference in the training data, let's compare the Iris data set with the directories of images. In Iris, each column is a feature that describest the flower. You can imagine I came up with these features manually, say, by measuring the flower with a ruler.\n",
    "![raw pixels](./assets/iris.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now by contrast, here's the training data in TensorFlow for Poets. It's just a list of labeled images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rose.png</td>\n",
       "      <td>Rose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tulipgarden.jpg</td>\n",
       "      <td>Tulip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>flowerfield.png</td>\n",
       "      <td>Sunflower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>whiteflower.jpg</td>\n",
       "      <td>Daisy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         File Name      Label\n",
       "0         rose.png       Rose\n",
       "1  tulipgarden.jpg      Tulip\n",
       "2  flowerfield.png  Sunflower\n",
       "3  whiteflower.jpg      Daisy\n",
       "4              ...        ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({\"File Name\":[\"rose.png\",\"tulipgarden.jpg\",\"flowerfield.png\",\"whiteflower.jpg\",\"...\"],\n",
    "              \"Label\":[\"Rose\",\"Tulip\",\"Sunflower\",\"Daisy\",\"...\"]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, a classifier is just a fucntion:\n",
    "```python\n",
    "f(x) = y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, _x_ is a 2D array of pixels from the image, and _y_ is a label like rose. Now when talking about deep learning, the classifier we'll be using is called a neural network. \n",
    "![neural network](./assets/neuralNetwork.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a high level, a neuarl network is just antoher type of classifier, like the nearest neighbor I classifier I wrote in the previous module. The difference is a neural network can learn more complex functions.  In this code labe, TensorFlow for poests takes care of setting up and training the neural network behind the scenes. This doesn't mean TensorFlow code is any harder to write than what I've worked with so far. In fact, *[TF Learn](http://tflearn.org/)* is a high level machine learning library on top of TensorFlow, and the syntax is similar to scikit-learn that has been shown so far.\n",
    "\n",
    "For example here's a code snippet that shows you how to import a neural network, train it, and use it to classify data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code cell is just hear for example \n",
    "# to show how simple it is to use tensorflow\n",
    "\n",
    "from sklearn import metrics, cross_validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "def main():\n",
    "    iris = learn.datasets.load_dataset('iris')\n",
    "    X_train, X_test, y_train, y_test = cross_validation.train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)\n",
    "\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    "\n",
    "    # Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "    classifier = learn.DNNClassifier(hidden_units=[10,20,10], n_classes=3, feature_columns=feature_columns)\n",
    "\n",
    "    # # Fit and predict.\n",
    "    classifier.fit(X_train, y_train, steps=200)\n",
    "    score = metrics.accuracy_score(y_test, classifier.predict(X_test))\n",
    "    print('Accuracy: {0:f}'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow in /anaconda3/lib/python3.7/site-packages (1.13.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /anaconda3/lib/python3.7/site-packages (from tensorflow) (1.0.7)\n",
      "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /anaconda3/lib/python3.7/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /anaconda3/lib/python3.7/site-packages (from tensorflow) (1.11.0)\n",
      "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /anaconda3/lib/python3.7/site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /anaconda3/lib/python3.7/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /anaconda3/lib/python3.7/site-packages (from tensorflow) (1.0.9)\n",
      "Requirement already satisfied, skipping upgrade: tensorboard<1.14.0,>=1.13.0 in /anaconda3/lib/python3.7/site-packages (from tensorflow) (1.13.1)\n",
      "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /anaconda3/lib/python3.7/site-packages (from tensorflow) (0.31.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /anaconda3/lib/python3.7/site-packages (from tensorflow) (1.15.1)\n",
      "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /anaconda3/lib/python3.7/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /anaconda3/lib/python3.7/site-packages (from tensorflow) (1.19.0)\n",
      "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /anaconda3/lib/python3.7/site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied, skipping upgrade: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /anaconda3/lib/python3.7/site-packages (from tensorflow) (1.13.0)\n",
      "Requirement already satisfied, skipping upgrade: h5py in /anaconda3/lib/python3.7/site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: setuptools in /anaconda3/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow) (40.2.0)\n",
      "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /anaconda3/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /anaconda3/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied, skipping upgrade: mock>=2.0.0 in /anaconda3/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied, skipping upgrade: pbr>=0.11 in /anaconda3/lib/python3.7/site-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'tensorflow-for-poets-2' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/googlecodelabs/tensorflow-for-poets-2\n",
    "\n",
    "!cd tensorflow-for-poets-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting up TensorFlow For Poets navigate to the section [(Re)training the network](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/?utm_campaign=chrome_series_machinelearning_063016&utm_source=gdev&utm_medium=yt-desc#3) to train the classifier.\n",
    "\n",
    "To do that start with this script.\n",
    "```UNIX\n",
    "python -m scripts.retrain \\\n",
    "  --bottleneck_dir=tf_files/bottlenecks \\\n",
    "  --how_many_training_steps=500 \\\n",
    "  --model_dir=tf_files/models/ \\\n",
    "  --summaries_dir=tf_files/training_summaries/\"${ARCHITECTURE}\" \\\n",
    "  --output_graph=tf_files/retrained_graph.pb \\\n",
    "  --output_labels=tf_files/retrained_labels.txt \\\n",
    "  --architecture=\"${ARCHITECTURE}\" \\\n",
    "  --image_dir=tf_files/flower_photos\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/travisgillespie/Desktop/data_analytics/github/machineLearning/ML6_train_image_classifier_with_TensorFlow'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# present working directory\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './tensorflow-for-poets-2'\n",
      "/Users/travisgillespie/Desktop/data_analytics/github/machineLearning/ML6_train_image_classifier_with_TensorFlow/tensorflow-for-poets-2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['~/Desktop/data_analytics/github/machineLearning/ML6_train_image_classifier_with_TensorFlow/tensorflow-for-poets-2',\n",
       " '~/Desktop/data_analytics/github/machineLearning/ML6_train_image_classifier_with_TensorFlow']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place the current dir on stack and change directory \n",
    "%pushd ./tensorflow-for-poets-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can use this command to Change to directory popped off the top of the stack.\n",
    "# %popd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['~/Desktop/data_analytics/github/machineLearning/ML6_train_image_classifier_with_TensorFlow/tensorflow-for-poets-2',\n",
       " '~/Desktop/data_analytics/github/machineLearning/ML6_train_image_classifier_with_TensorFlow']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the current directory stack.\n",
    "%dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/travisgillespie/Desktop/data_analytics/github/machineLearning/ML6_train_image_classifier_with_TensorFlow/tensorflow-for-poets-2\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  218M  100  218M    0     0  41.0M      0  0:00:05  0:00:05 --:--:-- 46.5M\n"
     ]
    }
   ],
   "source": [
    "# download photos by invoking the following command\n",
    "!curl http://download.tensorflow.org/example_images/flower_photos.tgz \\\n",
    "    | tar xz -C tf_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE.txt \u001b[1m\u001b[34mdaisy\u001b[m\u001b[m       \u001b[1m\u001b[34mdandelion\u001b[m\u001b[m   \u001b[1m\u001b[34mroses\u001b[m\u001b[m       \u001b[1m\u001b[34msunflowers\u001b[m\u001b[m  \u001b[1m\u001b[34mtulips\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "# confirm you have a copy of the flower photos\n",
    "!ls tf_files/flower_photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting variables in shell to recommended settings\n",
    "# by setting image size to 224 pixels\n",
    "# and relative size of the model as a fraction of largest MobilNet to 0.5\n",
    "# the MobileNet will retrain in a couple of minutes\n",
    "!IMAGE_SIZE=224\n",
    "!ARCHITECTURE=\"mobilenet_0.50_${IMAGE_SIZE}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/img/70170cbb89d318b1.png)\n",
    "This figure is further explained in [slides 84-89](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf).\n",
    "\n",
    "Video lecture covering the slides, starting around [1hr 4m](https://www.youtube.com/watch?v=DAOcjicFr1Y).\n",
    "\n",
    "This graph can be found displays the compultational complexity of 4 Deep Neural Network Models. The y-axis displays Top-1 Accuracy; where higher is betterr. The x-axis displays the number of operations, so the further to the right, the more ops that are being run (i.e. more computationally expensive). This size of the circle is your memorey usage. \n",
    "MobileNet has 16 points on the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR:tensorflow:Couldn't understand architecture name ''\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/anaconda3/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\r\n",
      "    \"__main__\", mod_spec)\r\n",
      "  File \"/anaconda3/lib/python3.7/runpy.py\", line 85, in _run_code\r\n",
      "    exec(code, run_globals)\r\n",
      "  File \"/Users/travisgillespie/Desktop/data_analytics/github/machineLearning/ML6_train_image_classifier_with_TensorFlow/tensorflow-for-poets-2/scripts/retrain.py\", line 1326, in <module>\r\n",
      "    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n",
      "  File \"/anaconda3/lib/python3.7/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n",
      "    _sys.exit(main(argv))\r\n",
      "  File \"/Users/travisgillespie/Desktop/data_analytics/github/machineLearning/ML6_train_image_classifier_with_TensorFlow/tensorflow-for-poets-2/scripts/retrain.py\", line 976, in main\r\n",
      "    model_info = create_model_info(FLAGS.architecture)\r\n",
      "  File \"/Users/travisgillespie/Desktop/data_analytics/github/machineLearning/ML6_train_image_classifier_with_TensorFlow/tensorflow-for-poets-2/scripts/retrain.py\", line 923, in create_model_info\r\n",
      "    raise ValueError('Unknown architecture', architecture)\r\n",
      "ValueError: ('Unknown architecture', '')\r\n"
     ]
    }
   ],
   "source": [
    "!python -m scripts.retrain \\\n",
    "  --bottleneck_dir=tf_files/bottlenecks \\\n",
    "  --how_many_training_steps=500 \\\n",
    "  --model_dir=tf_files/models/ \\\n",
    "  --summaries_dir=tf_files/training_summaries/\"${ARCHITECTURE}\" \\\n",
    "  --output_graph=tf_files/retrained_graph.pb \\\n",
    "  --output_labels=tf_files/retrained_labels.txt \\\n",
    "  --architecture=\"${ARCHITECTURE}\" \\\n",
    "  --image_dir=tf_files/flower_photos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [TensorFlow for Poets](https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/#0)\n",
    "* [TF Learn](http://tflearn.org/)\n",
    "* [download flowers (*i.e. training images*)]()\n",
    "* [Train Image Classifier with TensorFlow](https://www.youtube.com/watch?v=cSKfRcEDGUs&index=6&list=PLOU2XLYxmsIIuiBfYad6rFYQU_jL2ryal)\n",
    "* [tensorflow playground](http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.83261&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./assets/.png)\n",
    "_TensorFlow for Poets_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
